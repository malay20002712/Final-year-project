# -*- coding: utf-8 -*-
"""Detection_object.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ytz3Sqgc_hEistlCypETyjzQYItq_D9-
"""

!pip install tensorflow-gpu

import tensorflow as tf
print(tf.__version__)

"""# Current directory"""

cd /content/models/research

pwd

!protoc object_detection/protos/*.proto --python_out=.

!git clone https://github.com/cocodataset/cocoapi.git

cd cocoapi/PythonAPI

"""# to set up the path of cocoapi"""

!make

cp -r pycocotools /content/models/research

pwd

cd ..

pwd

cd ..

cp object_detection/packages/tf2/setup.py .

!python -m pip install --use-feature=2020-resolver .

pwd

!python object_detection/builders/model_builder_tf2_test.py

cd /content/Objects

pwd

cd ..

cd /content/yolo_weights

pwd

import tensorflow as tf
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from IPython.display import display
from seaborn import color_palette
import cv2

batch_norm_decay = 0.9
batch_norm_epilson = 1e-05
leaky_relu = 0.1 #number of neuron that die when it becomes 0
_anchors_ = [(10, 13), (16, 30), (33, 23),
            (30, 61), (62, 45), (59, 119),
            (116, 90), (156, 198), (373, 326)] #COCO datasets after k-means clustering
size_model = (416, 416)

def batch_norm(input_data, training_data, format_data):
    return tf.layers.batch_normalization(
        inputs=input_data, axis=1 if format_data == 'channels_first' else 3,
        momentum=batch_norm_decay, epsilon=batch_norm_epilson,
        scale=True, training=training_data)


def fixed_padding(input_data, kernel_size, format_data):
    pad_total = kernel_size - 1
    pad_beg = pad_total // 2
    pad_end = pad_total - pad_beg

    if format_data == 'channels_first':
        input_pad = tf.pad(input_data, [[0, 0], [0, 0],
                                        [pad_beg, pad_end],
                                        [pad_beg, pad_end]])
    else:
        input_pad = tf.pad(input_data, [[0, 0], [pad_beg, pad_end],
                                        [pad_beg, pad_end], [0, 0]])
    return input_pad


def conv2d_fixed_padding(input_data, filter_data, kernel_size, format_data, strides=1):
    if strides > 1:
        inputs = fixed_padding(inputs, kernel_size, format_data)

    return tf.layers.conv2d(
        inputs=inputs, filters=filter_data, kernel_size=kernel_size,
        strides=strides, padding=('SAME' if strides == 1 else 'VALID'),
        use_bias=False, data_format=format_data)

def darknet53_residual_block(input_data, filters, training, data_format,
                             strides=1):
    shortcut = input_data

    input_data = conv2d_fixed_padding(
        input_data, filters=filters, kernel_size=1, strides=strides,
        data_format=data_format)
    input_data = batch_norm(input_data, training=training, data_format=data_format)
    input_data = tf.nn.leaky_relu(input_data, alpha=leaky_relu)

    input_data = conv2d_fixed_padding(
        input_data, filters=2 * filters, kernel_size=3, strides=strides,
        data_format=data_format)
    input_data = batch_norm(input_data, training=training, data_format=data_format)
    input_data = tf.nn.leaky_relu(input_data, alpha=leaky_relu)

    input_data += shortcut

    return input_data


def darknet53(input_data, training_data, format_data):
    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3,
                                  data_format=format_data)
    inputs = batch_norm(inputs, training=training_data, data_format=format_data)
    inputs = tf.nn.leaky_relu(inputs, alpha=leaky_relu)
    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3,
                                  strides=2, data_format=format_data)
    inputs = batch_norm(inputs, training=training_data, data_format=format_data)
    inputs = tf.nn.leaky_relu(inputs, alpha=leaky_relu)

    inputs = darknet53_residual_block(inputs, filters=32, training=training_data,
                                      data_format=format_data)

    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3,
                                  strides=2, data_format=format_data)
    inputs = batch_norm(inputs, training=training_data, data_format=format_data)
    inputs = tf.nn.leaky_relu(inputs, alpha=leaky_relu)

    for _ in range(2):
        inputs = darknet53_residual_block(inputs, filters=64,
                                          training=training_data,
                                          data_format=format_data)

    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3,
                                  strides=2, data_format=format_data)
    inputs = batch_norm(inputs, training=training_data, data_format=format_data)
    inputs = tf.nn.leaky_relu(inputs, alpha=leaky_relu)

    for _ in range(8):
        inputs = darknet53_residual_block(inputs, filters=128,
                                          training=training_data,
                                          data_format=format_data)

    route1 = input_data

    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3,
                                  strides=2, data_format=format_data)
    inputs = batch_norm(inputs, training=training_data, data_format=format_data)
    inputs = tf.nn.leaky_relu(inputs, alpha=leaky_relu)

    for _ in range(8):
        inputs = darknet53_residual_block(inputs, filters=256,
                                          training=training_data,
                                          data_format=format_data)

    route2 = input_data

    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3,
                                  strides=2, data_format=format_data)
    inputs = batch_norm(inputs, training=training_data, data_format=format_data)
    inputs = tf.nn.leaky_relu(inputs, alpha=leaky_relu)

    for _ in range(4):
        inputs = darknet53_residual_block(inputs, filters=512,
                                          training=training_data,
                                          data_format=format_data)

    return route1, route2, input_data

"""# To group-up all the convulotion layer in the yolo layer"""

def convolution_block(input_data, filter_data, training_data, format_data):
    inputs = conv2d_fixed_padding(input_data, filters=filter_data, kernel_size=1,
                                  data_format=format_data)
    input_data= batch_norm(input_data, training=training_data, data_format=format_data)
    input_data = tf.nn.leaky_relu(input_data, alpha=leaky_relu)

    input_data = conv2d_fixed_padding(input_data, filters=2 * filter_data, kernel_size=3,
                                  data_format=format_data)
    input_data = batch_norm(input_data, training=training_data, data_format=format_data)
    input_data = tf.nn.leaky_relu(input_data, alpha=leaky_relu)

    input_data = conv2d_fixed_padding(input_data, filters=filter_data, kernel_size=1,
                                  data_format=format_data)
    input_data = batch_norm(input_data, training=training_data, data_format=format_data)
    input_data = tf.nn.leaky_relu(input_data, alpha=leaky_relu)

    input_data = conv2d_fixed_padding(input_data, filters=2 * filter_data, kernel_size=3,
                                  data_format=format_data)
    input_data = batch_norm(input_data, training=training_data, data_format=format_data)
    input_data = tf.nn.leaky_relu(input_data, alpha=leaky_relu)

    input_data = conv2d_fixed_padding(input_data, filters=filter_data, kernel_size=1,
                                  data_format=format_data)
    input_data = batch_norm(input_data, training=training_data, data_format=format_data)
    input_data = tf.nn.leaky_relu(input_data, alpha=leaky_relu)

    route = input_data

    input_data = conv2d_fixed_padding(input_data, filters=2 * filter_data, kernel_size=3,
                                  data_format=format_data)
    input_data = batch_norm(input_data, training=training_data, data_format=format_data)
    input_data = tf.nn.leaky_relu(input_data, alpha=leaky_relu)

    return route, input_data

def yolo_layer(input_data, n_classes, anchor, img_size, format_data):
    n_anchors = len(anchor)

    input_data = tf.layers.conv2d(input_data, filters=n_anchors * (5 + n_classes),
                              kernel_size=1, strides=1, use_bias=True,
                              data_format=format_data)

    shape = input_data.get_shape().as_list()
    grid_shape = shape[2:4] if format_data == 'channels_first' else shape[1:3]
    if format_data == 'channels_first':
        input_data = tf.transpose(inputs, [0, 2, 3, 1])
    input_data = tf.reshape(input_data, [-1, n_anchors * grid_shape[0] * grid_shape[1],
                                 5 + n_classes])

    strides = (img_size[0] // grid_shape[0], img_size[1] // grid_shape[1])

    box_centers, box_shapes, confidence, classes = \
        tf.split(input_data, [2, 2, 1, n_classes], axis=-1)

    x = tf.range(grid_shape[0], dtype=tf.float32)
    y = tf.range(grid_shape[1], dtype=tf.float32)
    x_offset, y_offset = tf.meshgrid(x, y)
    x_offset = tf.reshape(x_offset, (-1, 1))
    y_offset = tf.reshape(y_offset, (-1, 1))
    x_y_offset = tf.concat([x_offset, y_offset], axis=-1)
    x_y_offset = tf.tile(x_y_offset, [1, n_anchors])
    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])
    box_centers = tf.nn.sigmoid(box_centers)
    box_centers = (box_centers + x_y_offset) * strides

    anchors = tf.tile(anchor, [grid_shape[0] * grid_shape[1], 1])
    box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)

    confidence = tf.nn.sigmoid(confidence)

    classes = tf.nn.sigmoid(classes)

    input_data = tf.concat([box_centers, box_shapes,
                        confidence, classes], axis=-1)

    return input_data

def upsample(input_data,shape_out, format_data):
    if format_data == 'channels_first':
        input_data = tf.transpose(input_data, [0, 2, 3, 1])
        new_height = shape_out[3]
        new_width = shape_out[2]
    else:
        new_height = shape_out[2]
        new_width = shape_out[1]

    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))

    if format_data == 'channels_first':
        input_data = tf.transpose(input_data, [0, 3, 1, 2])

    return input_data

def build_boxes(inputs):
    center_x, center_y, width, height, confidence, classes = \
        tf.split(inputs, [1, 1, 1, 1, 1, -1], axis=-1)

    top_left_x = center_x - width / 2
    top_left_y = center_y - height / 2
    bottom_right_x = center_x + width / 2
    bottom_right_y = center_y + height / 2

    boxes = tf.concat([top_left_x, top_left_y,
                       bottom_right_x, bottom_right_y,
                       confidence, classes], axis=-1)

    return boxes


def non_max_suppression(input_data, n_classes, max_output_size, intersection_threshold,
                        threshold):
    batch = tf.unstack(input_data)
    boxes_dicts = []
    for boxes in batch:
        boxes = tf.boolean_mask(boxes, boxes[:, 4] > threshold)
        classes = tf.argmax(boxes[:, 5:], axis=-1)
        classes = tf.expand_dims(tf.to_float(classes), axis=-1)
        boxes = tf.concat([boxes[:, :5], classes], axis=-1)

        boxes_dict = dict()
        for cls in range(n_classes):
            mask = tf.equal(boxes[:, 5], cls)
            mask_shape = mask.get_shape()
            if mask_shape.ndims != 0:
                class_boxes = tf.boolean_mask(boxes, mask)
                boxes_coords, boxes_conf_scores, _ = tf.split(class_boxes,
                                                              [4, 1, -1],
                                                              axis=-1)
                boxes_conf_scores = tf.reshape(boxes_conf_scores, [-1])
                indices = tf.image.non_max_suppression(boxes_coords,
                                                       boxes_conf_scores,
                                                       max_output_size,
                                                       intersection_threshold)
                class_boxes = tf.gather(class_boxes, indices)
                boxes_dict[cls] = class_boxes[:, :5]

        boxes_dicts.append(boxes_dict)

    return boxes_dicts

class Yolo_v3:
    def __init__(self, n_classes, model_size, max_output_size, intersection_threshold,
                 threshold, format_data=None):
        data_format = ''
        if not data_format:
            if tf.test.is_built_with_cuda():
                data_format = 'channels_first'
            else:
                data_format = 'channels_last'

        self.n_classes = n_classes
        self.model_size = model_size
        self.max_output_size = max_output_size
        self.intersection_threshold = intersection_threshold
        self.threshold = threshold
        self.format_data = format_data

    def __call__(self, input_data, training_data):
        with tf.variable_scope('yolo_v3_model'):
            if self.data_format == 'channels_first':
                input_data = tf.transpose(input_data, [0, 3, 1, 2])

            input_data = input_data / 255

            route1, route2, input_data = darknet53(input_data, training=training_data,
                                               data_format=self.data_format)

            route, input_data = convolution_block(
                input_data, filters=512, training=training_data,
                data_format=self.data_format)
            detect1 = yolo_layer(input_data, n_classes=self.n_classes,
                                 anchors=_anchors_[6:9],
                                 img_size=self.model_size,
                                 data_format=self.data_format)

            input_data = conv2d_fixed_padding(route, filters=256, kernel_size=1,
                                          data_format=self.data_format)
            input_data = batch_norm(input_data, training=training_data,
                                data_format=self.data_format)
            inputs = tf.nn.leaky_relu(input_data, alpha=leaky_relu)
            upsample_size = route2.get_shape().as_list()
            input_data = upsample(input_data, out_shape=upsample_size,
                              data_format=self.data_format)
            axis = 1 if self.data_format == 'channels_first' else 3
            input_data = tf.concat([inputs, route2], axis=axis)
            route, input_data = convolution_block(
                input_data, filters=256, training=training_data,
                data_format=self.data_format)
            detect2 = yolo_layer(input_data, n_classes=self.n_classes,
                                 anchors=_anchors_[3:6],
                                 img_size=self.model_size,
                                 data_format=self.data_format)

            input_data = conv2d_fixed_padding(route, filters=128, kernel_size=1,
                                          data_format=self.data_format)
            input_data = batch_norm(input_data, training=training_data,
                                data_format=self.data_format)
            input_data = tf.nn.leaky_relu(input_data, alpha=leaky_relu)
            upsample_size = route1.get_shape().as_list()
            input_data = upsample(inputs, out_shape=upsample_size,
                              data_format=self.data_format)
            input_data = tf.concat([input_data, route1], axis=axis)
            route, inputs = convolution_block(
                inputs, filters=128, training=training_data,
                data_format=self.data_format)
            detect3 = yolo_layer(input_data, n_classes=self.n_classes,
                                 anchors=_anchors_[0:3],
                                 img_size=self.model_size,
                                 data_format=self.data_format)

            input_data = tf.concat([detect1, detect2, detect3], axis=1)

            input_data = build_boxes(inputs)

            boxes_dicts = non_max_suppression(
                input_data, n_classes=self.n_classes,
                max_output_size=self.max_output_size,
                intersection_threshold=self.iou_threshold,
                threshold=self.confidence_threshold)
            return boxes_dicts

def load_images(img_names, model_size):
    imgs = []

    for img_name in img_names:
        img = Image.open(img_name)
        img = img.resize(size=model_size)
        img = np.array(img, dtype=np.float32)
        img = np.expand_dims(img, axis=0)
        imgs.append(img)

    imgs = np.concatenate(imgs)

    return imgs


def load_class_names(file_name):
    with open(file_name, 'r') as f:
        class_names = f.read().splitlines()
    return class_names


def draw_boxes(img_names, boxes_dicts, class_names, model_size):
    colors = ((np.array(color_palette("hls", 80)) * 255)).astype(np.uint8)
    for num, img_name, boxes_dict in zip(range(len(img_names)), img_names,
                                         boxes_dicts):
        img = Image.open(img_name)
        draw = ImageDraw.Draw(img)
        font = ImageFont.truetype(font='../input/futur.ttf',
                                  size=(img.size[0] + img.size[1]) // 100)
        resize_factor = \
            (img.size[0] / model_size[0], img.size[1] / model_size[1])
        for cls in range(len(class_names)):
            boxes = boxes_dict[cls]
            if np.size(boxes) != 0:
                color = colors[cls]
                for box in boxes:
                    xy, confidence = box[:4], box[4]
                    xy = [xy[i] * resize_factor[i % 2] for i in range(4)]
                    x0, y0 = xy[0], xy[1]
                    thickness = (img.size[0] + img.size[1]) // 200
                    for t in np.linspace(0, 1, thickness):
                        xy[0], xy[1] = xy[0] + t, xy[1] + t
                        xy[2], xy[3] = xy[2] - t, xy[3] - t
                        draw.rectangle(xy, outline=tuple(color))
                    text = '{} {:.1f}%'.format(class_names[cls],
                                               confidence * 100)
                    text_size = draw.textsize(text, font=font)
                    draw.rectangle(
                        [x0, y0 - text_size[1], x0 + text_size[0], y0],
                        fill=tuple(color))
                    draw.text((x0, y0 - text_size[1]), text, fill='black',
                              font=font)

        display(img)

def load_weights(variables, file_name):
    with open(file_name, "rb") as f:
        np.fromfile(f, dtype=np.int32, count=5)
        weights = np.fromfile(f, dtype=np.float32)

        assign_ops = []
        ptr = 0

        for i in range(52):
            conv_var = variables[5 * i]
            gamma, beta, mean, variance = variables[5 * i + 1:5 * i + 5]
            batch_norm_vars = [beta, gamma, mean, variance]

            for var in batch_norm_vars:
                shape = var.shape.as_list()
                num_params = np.prod(shape)
                var_weights = weights[ptr:ptr + num_params].reshape(shape)
                ptr += num_params
                assign_ops.append(tf.assign(var, var_weights))

            shape = conv_var.shape.as_list()
            num_params = np.prod(shape)
            var_weights = weights[ptr:ptr + num_params].reshape(
                (shape[3], shape[2], shape[0], shape[1]))
            var_weights = np.transpose(var_weights, (2, 3, 1, 0))
            ptr += num_params
            assign_ops.append(tf.assign(conv_var, var_weights))
        ranges = [range(0, 6), range(6, 13), range(13, 20)]
        unnormalized = [6, 13, 20]
        for j in range(3):
            for i in ranges[j]:
                current = 52 * 5 + 5 * i + j * 2
                conv_var = variables[current]
                gamma, beta, mean, variance =  \
                    variables[current + 1:current + 5]
                batch_norm_vars = [beta, gamma, mean, variance]

                for var in batch_norm_vars:
                    shape = var.shape.as_list()
                    num_params = np.prod(shape)
                    var_weights = weights[ptr:ptr + num_params].reshape(shape)
                    ptr += num_params
                    assign_ops.append(tf.assign(var, var_weights))

                shape = conv_var.shape.as_list()
                num_params = np.prod(shape)
                var_weights = weights[ptr:ptr + num_params].reshape(
                    (shape[3], shape[2], shape[0], shape[1]))
                var_weights = np.transpose(var_weights, (2, 3, 1, 0))
                ptr += num_params
                assign_ops.append(tf.assign(conv_var, var_weights))

            bias = variables[52 * 5 + unnormalized[j] * 5 + j * 2 + 1]
            shape = bias.shape.as_list()
            num_params = np.prod(shape)
            var_weights = weights[ptr:ptr + num_params].reshape(shape)
            ptr += num_params
            assign_ops.append(tf.assign(bias, var_weights))

            conv_var = variables[52 * 5 + unnormalized[j] * 5 + j * 2]
            shape = conv_var.shape.as_list()
            num_params = np.prod(shape)
            var_weights = weights[ptr:ptr + num_params].reshape(
                (shape[3], shape[2], shape[0], shape[1]))
            var_weights = np.transpose(var_weights, (2, 3, 1, 0))
            ptr += num_params
            assign_ops.append(tf.assign(conv_var, var_weights))

    return assign_ops

"""# images to upload in the analytics"""

images_to_be_detected = ['/content/dog.jpg', '/content/office.jpg']
for images in images_to_be_detected: display(Image.open(images))

!pip install tensorflow.placeholder

batch_size_element = len(images_to_be_detected)
batch = load_images(images_to_be_detected, model_size = size_model)
name_class = load_class_names('/content/coco.names')
number_of_class = len(name_class)
max_size_output = 10
intersection_threshold = 0.5
threshold = 0.5
model_making = Yolo_v3(n_classes=name_class, model_size=size_model,
                max_output_size=max_size_output,
                intersection_threshold=intersection_threshold,
                threshold=threshold)
input_imgbar = tf.placeholder(tf.float32, [batch_size_element, 416, 416, 3])
image_detection = model_making(input_imgbar, training = False)
image_variable = tf.global_variables(scope='yolo_v3_model')

from IPython.display import Image
with open('/content/detections.gif','rb') as f:
    display(Image(data=f.read(), format='png'))

